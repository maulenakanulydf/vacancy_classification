{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83c307e1-934f-4d52-a93f-de61af2623c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3944592e-d12e-4d72-814a-99b1b66efbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea7a95d2-71b8-46a2-828b-9cef572a9dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3e73fba-f7de-45bd-b680-e3a653c71407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5dc8ff1-e9b8-43a4-8077-f126d47ed781",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5567d2d1-d41a-425b-aa4b-2b211b343f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "399b08f9-edf9-4dc5-aa0f-d47660939481",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../dataset/with_prefix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f551b0b6-1f43-4c6b-8f8e-27214e203e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>response</th>\n",
       "      <th>natasha_response</th>\n",
       "      <th>class</th>\n",
       "      <th>natasha_response_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13246</td>\n",
       "      <td>Финансовый аналитик</td>\n",
       "      <td>обязанности организовывает управление движение...</td>\n",
       "      <td>организовывает управление движением финансовых...</td>\n",
       "      <td>организовывать управление движение финансовый ...</td>\n",
       "      <td>0</td>\n",
       "      <td>организовывать управление движение финансовый ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14266</td>\n",
       "      <td>Финансовый менеджер</td>\n",
       "      <td>обязанности составление бюджета доходов бюджет...</td>\n",
       "      <td>Составление бюджета доходов и расходов, контро...</td>\n",
       "      <td>составление бюджет доход и расход , контроль и...</td>\n",
       "      <td>0</td>\n",
       "      <td>составление бюджет доход расход исполнение при...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>14674</td>\n",
       "      <td>Финансовый аналитик</td>\n",
       "      <td>уважаемый кандидат компания alem sauda ltd рад...</td>\n",
       "      <td>Разработка и внедрение внутренних регламентиру...</td>\n",
       "      <td>разработка и внедрение внутренний регламентиро...</td>\n",
       "      <td>0</td>\n",
       "      <td>разработка внедрение внутренний регламентирова...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>15042</td>\n",
       "      <td>Старший финансовый аналитик</td>\n",
       "      <td>требования высшее финансовое экономическое обр...</td>\n",
       "      <td>Осуществлять работу экономическому планировани...</td>\n",
       "      <td>осуществлять работа экономический планирование...</td>\n",
       "      <td>0</td>\n",
       "      <td>осуществлять экономический ирование выявлять и...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>16179</td>\n",
       "      <td>Финансовый аналитик на проект Sandyq</td>\n",
       "      <td>обязанности формирование управленческой отчетн...</td>\n",
       "      <td>формирование управленческой отчетности, анализ...</td>\n",
       "      <td>формирование управленческий отчетность , анали...</td>\n",
       "      <td>0</td>\n",
       "      <td>формирование управленческий отчетность анализ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16897</th>\n",
       "      <td>16897</td>\n",
       "      <td>16897</td>\n",
       "      <td>17636</td>\n",
       "      <td>82155</td>\n",
       "      <td>Снабженец-логист</td>\n",
       "      <td>обязанности организация закупки соответствующи...</td>\n",
       "      <td>Организация закупки товаров, организация долго...</td>\n",
       "      <td>организация закупка товар , организация долгос...</td>\n",
       "      <td>75</td>\n",
       "      <td>закупка товар долгосрочный сотрудничество пост...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16898</th>\n",
       "      <td>16898</td>\n",
       "      <td>16898</td>\n",
       "      <td>17637</td>\n",
       "      <td>82695</td>\n",
       "      <td>Логист</td>\n",
       "      <td>обязанности поиск автотранспорта перевозкам рф...</td>\n",
       "      <td>Поиск автотранспорта, перевозки РФ РК внутри Р...</td>\n",
       "      <td>поиск автотранспорт , перевозка рф рк внутри р...</td>\n",
       "      <td>75</td>\n",
       "      <td>поиск автотранспорт перевозка рф рк внутри рк ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16899</th>\n",
       "      <td>16899</td>\n",
       "      <td>16899</td>\n",
       "      <td>17638</td>\n",
       "      <td>82941</td>\n",
       "      <td>Специалист по логистике</td>\n",
       "      <td>обязанности отвечать звонки обрабатывать заявк...</td>\n",
       "      <td>Отвечать звонки, обрабатывать заявки, презента...</td>\n",
       "      <td>отвечать звонок , обрабатывать заявка , презен...</td>\n",
       "      <td>75</td>\n",
       "      <td>отвечать звонок обрабатывать заявка презентаци...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16900</th>\n",
       "      <td>16900</td>\n",
       "      <td>16900</td>\n",
       "      <td>17639</td>\n",
       "      <td>83572</td>\n",
       "      <td>Специалист по логистике</td>\n",
       "      <td>обязанности организация планирование контроль ...</td>\n",
       "      <td>Организация, планирование, контроль и регулиро...</td>\n",
       "      <td>организация , планирование , контроль и регули...</td>\n",
       "      <td>75</td>\n",
       "      <td>ирование регулирование доставка товар оптималь...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16901</th>\n",
       "      <td>16901</td>\n",
       "      <td>16901</td>\n",
       "      <td>17640</td>\n",
       "      <td>85625</td>\n",
       "      <td>Специалист отдела закупок и логистики</td>\n",
       "      <td>обязанности составлять прогнозы планы вести по...</td>\n",
       "      <td>Составлять прогнозы, планы, вести поиск выгодн...</td>\n",
       "      <td>составлять прогноз , план , вести поиск выгодн...</td>\n",
       "      <td>75</td>\n",
       "      <td>составлять прогноз вести поиск выный предложен...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16902 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0     id  \\\n",
       "0                 0             0           0  13246   \n",
       "1                 1             1           1  14266   \n",
       "2                 2             2           2  14674   \n",
       "3                 3             3           3  15042   \n",
       "4                 4             4           4  16179   \n",
       "...             ...           ...         ...    ...   \n",
       "16897         16897         16897       17636  82155   \n",
       "16898         16898         16898       17637  82695   \n",
       "16899         16899         16899       17638  82941   \n",
       "16900         16900         16900       17639  83572   \n",
       "16901         16901         16901       17640  85625   \n",
       "\n",
       "                                        name  \\\n",
       "0                        Финансовый аналитик   \n",
       "1                        Финансовый менеджер   \n",
       "2                        Финансовый аналитик   \n",
       "3                Старший финансовый аналитик   \n",
       "4       Финансовый аналитик на проект Sandyq   \n",
       "...                                      ...   \n",
       "16897                       Снабженец-логист   \n",
       "16898                                 Логист   \n",
       "16899                Специалист по логистике   \n",
       "16900                Специалист по логистике   \n",
       "16901  Специалист отдела закупок и логистики   \n",
       "\n",
       "                                             description  \\\n",
       "0      обязанности организовывает управление движение...   \n",
       "1      обязанности составление бюджета доходов бюджет...   \n",
       "2      уважаемый кандидат компания alem sauda ltd рад...   \n",
       "3      требования высшее финансовое экономическое обр...   \n",
       "4      обязанности формирование управленческой отчетн...   \n",
       "...                                                  ...   \n",
       "16897  обязанности организация закупки соответствующи...   \n",
       "16898  обязанности поиск автотранспорта перевозкам рф...   \n",
       "16899  обязанности отвечать звонки обрабатывать заявк...   \n",
       "16900  обязанности организация планирование контроль ...   \n",
       "16901  обязанности составлять прогнозы планы вести по...   \n",
       "\n",
       "                                                response  \\\n",
       "0      организовывает управление движением финансовых...   \n",
       "1      Составление бюджета доходов и расходов, контро...   \n",
       "2      Разработка и внедрение внутренних регламентиру...   \n",
       "3      Осуществлять работу экономическому планировани...   \n",
       "4      формирование управленческой отчетности, анализ...   \n",
       "...                                                  ...   \n",
       "16897  Организация закупки товаров, организация долго...   \n",
       "16898  Поиск автотранспорта, перевозки РФ РК внутри Р...   \n",
       "16899  Отвечать звонки, обрабатывать заявки, презента...   \n",
       "16900  Организация, планирование, контроль и регулиро...   \n",
       "16901  Составлять прогнозы, планы, вести поиск выгодн...   \n",
       "\n",
       "                                        natasha_response  class  \\\n",
       "0      организовывать управление движение финансовый ...      0   \n",
       "1      составление бюджет доход и расход , контроль и...      0   \n",
       "2      разработка и внедрение внутренний регламентиро...      0   \n",
       "3      осуществлять работа экономический планирование...      0   \n",
       "4      формирование управленческий отчетность , анали...      0   \n",
       "...                                                  ...    ...   \n",
       "16897  организация закупка товар , организация долгос...     75   \n",
       "16898  поиск автотранспорт , перевозка рф рк внутри р...     75   \n",
       "16899  отвечать звонок , обрабатывать заявка , презен...     75   \n",
       "16900  организация , планирование , контроль и регули...     75   \n",
       "16901  составлять прогноз , план , вести поиск выгодн...     75   \n",
       "\n",
       "                              natasha_response_stopwords  \n",
       "0      организовывать управление движение финансовый ...  \n",
       "1      составление бюджет доход расход исполнение при...  \n",
       "2      разработка внедрение внутренний регламентирова...  \n",
       "3      осуществлять экономический ирование выявлять и...  \n",
       "4      формирование управленческий отчетность анализ ...  \n",
       "...                                                  ...  \n",
       "16897  закупка товар долгосрочный сотрудничество пост...  \n",
       "16898  поиск автотранспорт перевозка рф рк внутри рк ...  \n",
       "16899  отвечать звонок обрабатывать заявка презентаци...  \n",
       "16900  ирование регулирование доставка товар оптималь...  \n",
       "16901  составлять прогноз вести поиск выный предложен...  \n",
       "\n",
       "[16902 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac596ec4-4461-43d4-86da-d8603421d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_row = df[df['class'] == 0].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d61a8c5-ebcc-41f8-90db-0cae5e899401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'организовывать управление движение финансовый ресурс регулирование финансовый отношение разработка норматив оборотный средство движение финансовый средство составление отчетность правильность составление своевременность предоставление отчетный рациональный денежный средство минимизация расход финансовый экономический стаж область финансовый деятельность обязательно Финансовый аналитик'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_row['natasha_response_stopwords'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56c183b2-c344-4573-b2ff-55878cf82634",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyterhub/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=76, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('DeepPavlov/rubert-base-cased')\n",
    "model = AutoModelForSequenceClassification.from_pretrained('DeepPavlov/rubert-base-cased', num_labels=76, output_attentions=True, output_hidden_states=True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cd48d62-a842-4758-8ef1-88997684c401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(description, tokenizer, max_length=512):\n",
    "    return tokenizer(description.tolist(), padding='max_length', truncation=True, max_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35d31e3a-cd2a-4816-b684-9e872016a095",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['natasha_response_stopwords'], df['class'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b3369af-248d-4b83-94db-6930ddefe00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5952f682-a1b3-44a2-9651-9c16c9d88b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list = X_train.astype(str).tolist()\n",
    "X_test_list = X_test.astype(str).tolist()\n",
    "\n",
    "# Define your tokenize function (without the .tolist() call)\n",
    "def tokenize_function(description, tokenizer, max_length=512):\n",
    "    return tokenizer(description, padding='max_length', truncation=True, max_length=max_length)\n",
    "\n",
    "# Tokenize the lists of strings\n",
    "train_encodings = tokenize_function(X_train_list, tokenizer)\n",
    "test_encodings = tokenize_function(X_test_list, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c1bda16-0812-4d20-bb88-2256fc932344",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = torch.tensor(y_train.values)\n",
    "test_labels = torch.tensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a437b80a-4263-4212-ac2b-795a5e04ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "904c354a-9486-4be5-8447-4f15abd94bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = JobDataset(train_encodings, y_train)\n",
    "test_dataset = JobDataset(test_encodings, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2733b2d-25a2-4131-943e-01708b361011",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cbb36200-d2ee-47e2-a895-746b966c512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfff2601-8396-4577-897a-1481895964ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, path=\"checkpoint.pth\"):\n",
    "    checkpoint = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'epoch': epoch\n",
    "    }\n",
    "    torch.save(checkpoint, path)\n",
    "    print(f\"Сохранен snapshot на эпохе {epoch} в {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a05f45d-27f1-47a9-8995-a43c2b14c209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(path, model, optimizer):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    print(f\"Загружен snapshot с {epoch}-й эпохи\")\n",
    "    return epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "188a7fbb-4a10-4fb9-91f8-59dc509b3d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, train_loader, test_loader, optimizer, device, num_epochs=7, gradient_accumulation_steps=4, save_path=\"checkpoint.pth\"):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        optimizer.zero_grad()  \n",
    "\n",
    "        train_loader_tqdm = tqdm(train_loader, desc=f\"Эпоха {epoch+1}/{num_epochs} - Тренировка\", leave=False)\n",
    "\n",
    "        for step, batch in enumerate(train_loader_tqdm):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss = loss / gradient_accumulation_steps  \n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            if (step + 1) % gradient_accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()  \n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "\n",
    "        test_loader_tqdm = tqdm(test_loader, desc=f\"Эпоха {epoch+1}/{num_epochs} - Валидация\", leave=False)\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader_tqdm:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(test_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        print(f\"Эпоха {epoch+1}/{num_epochs} | Тренировочная потеря: {avg_train_loss:.4f} | Валид потеря: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        save_checkpoint(model, optimizer, epoch+1, path=f\"{save_path}_epoch_{epoch+1}.pth\")\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9db7eef6-218e-4195-85b4-5c5515fca83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = \"../../snapshoot/model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e966c831-39cf-40db-b785-00ffd578eaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Эпоха 1/5 - Тренировка:   0%|          | 0/1691 [00:00<?, ?it/s]BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 1/5 | Тренировочная потеря: 0.6686 | Валид потеря: 1.3193\n",
      "Сохранен snapshot на эпохе 1 в checkpoint_epoch_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 2/5 | Тренировочная потеря: 0.2447 | Валид потеря: 0.7359\n",
      "Сохранен snapshot на эпохе 2 в checkpoint_epoch_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 3/5 | Тренировочная потеря: 0.1458 | Валид потеря: 0.5883\n",
      "Сохранен snapshot на эпохе 3 в checkpoint_epoch_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 4/5 | Тренировочная потеря: 0.1060 | Валид потеря: 0.5850\n",
      "Сохранен snapshot на эпохе 4 в checkpoint_epoch_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 5/5 | Тренировочная потеря: 0.0804 | Валид потеря: 0.5547\n",
      "Сохранен snapshot на эпохе 5 в checkpoint_epoch_5.pth\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = train_model(model, train_loader, test_loader, optimizer, device, num_epochs=5, gradient_accumulation_steps=4, save_path=\"checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3b49cc0-3805-48a8-880a-7afcf2b35ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8524\n",
      "Precision: 0.8577\n",
      "Recall: 0.8524\n",
      "F1-score: 0.8525\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions, average='weighted')  \n",
    "    recall = recall_score(all_labels, all_predictions, average='weighted')       \n",
    "    f1 = f1_score(all_labels, all_predictions, average='weighted')                \n",
    "\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1-score: {f1:.4f}')\n",
    "\n",
    "evaluate_model(model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8efde1cf-f120-42f5-bbc4-92c63cf0b824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23699/2814753524.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружен snapshot с 3-й эпохи\n"
     ]
    }
   ],
   "source": [
    "epoch = load_checkpoint('checkpoint_epoch_3.pth', model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3664560-497c-483d-b6d9-f7e87f129280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8388\n",
      "Precision: 0.8402\n",
      "Recall: 0.8388\n",
      "F1-score: 0.8335\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13558baf-9dcb-4afb-b83f-e4768905e3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../../dataset/test_data_0_406.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8ac9cc3-dafa-47e3-adf3-0de1c6ee7dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23699/2814753524.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружен snapshot с 3-й эпохи\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Предсказания: 100%|██████████| 4343/4343 [32:02<00:00,  2.26it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def tokenize_descriptions(descriptions, tokenizer, max_length=512):\n",
    "    return tokenizer(descriptions.tolist(), padding='max_length', truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "\n",
    "encodings = tokenize_descriptions(test_data['clean_description'], tokenizer)\n",
    "\n",
    "class DescriptionDataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "description_dataset = DescriptionDataset(encodings)\n",
    "description_loader = DataLoader(description_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "def predict(model, data_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Предсказания\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            \n",
    "            predicted_classes = torch.argmax(probs, dim=-1)\n",
    "            \n",
    "            predictions.extend(predicted_classes.cpu().numpy())\n",
    "            probabilities.extend(probs.cpu().numpy())\n",
    "    \n",
    "    return predictions, probabilities\n",
    "epoch = load_checkpoint('checkpoint_epoch_3.pth', model, optimizer)\n",
    "predicted_classes, predicted_probabilities = predict(model, description_loader, device)\n",
    "\n",
    "test_data['predicted_class'] = predicted_classes\n",
    "test_data['predicted_probability'] = [max(prob) for prob in predicted_probabilities]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ea34ceb-1941-47fb-b2db-b936ee7db699",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = test_data.groupby(['predicted_class']).mean('predicted_probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "44eac30c-af62-4c0e-8057-2d00ff083e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>predicted_probability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted_class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26751.000000</td>\n",
       "      <td>7.805280e+05</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>0.188523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23828.923077</td>\n",
       "      <td>5.237138e+05</td>\n",
       "      <td>85.461538</td>\n",
       "      <td>0.560894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23949.060665</td>\n",
       "      <td>8.976478e+05</td>\n",
       "      <td>109.365949</td>\n",
       "      <td>0.693482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20416.294372</td>\n",
       "      <td>6.802178e+05</td>\n",
       "      <td>80.969697</td>\n",
       "      <td>0.374523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29493.571429</td>\n",
       "      <td>1.046879e+06</td>\n",
       "      <td>141.285714</td>\n",
       "      <td>0.397105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>60756.373164</td>\n",
       "      <td>7.969419e+05</td>\n",
       "      <td>78.110676</td>\n",
       "      <td>0.606423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>59690.582463</td>\n",
       "      <td>6.520419e+05</td>\n",
       "      <td>72.757829</td>\n",
       "      <td>0.279594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>61027.628431</td>\n",
       "      <td>5.846800e+05</td>\n",
       "      <td>74.787382</td>\n",
       "      <td>0.402610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>41060.740560</td>\n",
       "      <td>3.281475e+05</td>\n",
       "      <td>46.658952</td>\n",
       "      <td>0.648260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>53284.131276</td>\n",
       "      <td>3.398501e+05</td>\n",
       "      <td>80.817907</td>\n",
       "      <td>0.687353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Unnamed: 0            id       class  predicted_probability\n",
       "predicted_class                                                               \n",
       "0                26751.000000  7.805280e+05  108.000000               0.188523\n",
       "1                23828.923077  5.237138e+05   85.461538               0.560894\n",
       "2                23949.060665  8.976478e+05  109.365949               0.693482\n",
       "3                20416.294372  6.802178e+05   80.969697               0.374523\n",
       "4                29493.571429  1.046879e+06  141.285714               0.397105\n",
       "...                       ...           ...         ...                    ...\n",
       "71               60756.373164  7.969419e+05   78.110676               0.606423\n",
       "72               59690.582463  6.520419e+05   72.757829               0.279594\n",
       "73               61027.628431  5.846800e+05   74.787382               0.402610\n",
       "74               41060.740560  3.281475e+05   46.658952               0.648260\n",
       "75               53284.131276  3.398501e+05   80.817907               0.687353\n",
       "\n",
       "[74 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ec3c8694-bb8a-4937-926f-3ffc57f74d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_excel('asa.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d683e043-ce81-4806-ad7a-acc2ef877189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
       "       37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54,\n",
       "       55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72,\n",
       "       73, 74, 75],\n",
       "      dtype='int64', name='predicted_class')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['predicted_class'].value_counts().sort_index().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6454d3d-d7dd-468c-8915-422a7e138a49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
