{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "0b55b07c-3a16-4aaa-a25d-5a45023234c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered['cnt'] = df_filtered['description'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "ba2b22de-d054-46df-b2ad-c446b4c34ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_filtered[df_filtered['cnt']<250]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26783bc-4551-44aa-aada-889445a10a66",
   "metadata": {},
   "source": [
    "**Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aba8db6d-a2d0-40c7-b2fd-6d577e87994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "876ecc50-a9c9-46fe-8d67-99ddf537648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('before_extract/techer_uni.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "177ac2f7-87dd-4afd-af87-f2a09e4182dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "def preprocess(sentence):\n",
    "    soup = bs(sentence, features=\"html.parser\")\n",
    "    sentence = soup.get_text()\n",
    "    \n",
    "    sentence = str(sentence).lower()\n",
    "    sentence = sentence.replace('{html}',\"\")\n",
    "    \n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', sentence)\n",
    "    rem_url = re.sub(r'http\\S+', '', cleantext)\n",
    "    rem_num = re.sub('[0-9]+', '', rem_url)\n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r'\\w+|[.,]')\n",
    "    tokens = tokenizer.tokenize(rem_num)\n",
    "    \n",
    "    filtered_words = [w for w in tokens if not w in stopwords.words('russian')]\n",
    "\n",
    "    processed_text = re.sub(r'\\s+([.,])', r'\\1', \" \".join(filtered_words))\n",
    "    \n",
    "    processed_text = re.sub(r'\\.\\s*\\.', '.', processed_text)\n",
    "    \n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9328da4b-8f32-46e8-8239-9f6f625d6ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 441/17685 [00:06<03:36, 79.68it/s]/tmp/ipykernel_30458/476461610.py:10: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = bs(sentence, features=\"html.parser\")\n",
      "100%|██████████| 17685/17685 [05:11<00:00, 56.71it/s]\n"
     ]
    }
   ],
   "source": [
    "df['extr'] = df['description'].progress_apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8bb52d3-acb9-4461-8146-29db26f3521a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyterhub/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/maulen_auth0_auth0/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/opt/jupyterhub/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "data = df  \n",
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "def summarize_text(text, num_sentences=4):\n",
    "    sentences = sent_tokenize(text, language='russian')\n",
    "    \n",
    "    sentence_embeddings = model.encode(sentences)\n",
    "    \n",
    "    similarity_matrix = cosine_similarity(sentence_embeddings)\n",
    "    \n",
    "    sentence_scores = similarity_matrix.sum(axis=1)\n",
    "    \n",
    "    top_sentence_indices = np.argsort(sentence_scores)[-num_sentences:]\n",
    "    \n",
    "    top_sentence_indices = sorted(top_sentence_indices)\n",
    "    \n",
    "    summary_sentences = [sentences[i].strip() for i in top_sentence_indices if sentences[i].strip()]\n",
    "    summary = \" \".join(summary_sentences)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e87441c-8db5-437b-ae52-53b3f4567db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17685/17685 [10:43<00:00, 27.48it/s]\n"
     ]
    }
   ],
   "source": [
    "df['lm'] = df['extr'].progress_apply(summarize_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
